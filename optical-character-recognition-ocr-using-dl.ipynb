{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-19T02:53:27.906791Z",
     "iopub.status.busy": "2023-12-19T02:53:27.905527Z",
     "iopub.status.idle": "2023-12-19T02:53:27.914375Z",
     "shell.execute_reply": "2023-12-19T02:53:27.913232Z",
     "shell.execute_reply.started": "2023-12-19T02:53:27.906745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Default libraries, packages for data management, visualization and Computer vision libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Sklearn package -> function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Tensorflow packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense, Dropout, Conv2D, MaxPool2D, \n",
    "                                     BatchNormalization, Flatten, GlobalAveragePooling2D, Input)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.applications import EfficientNetB7, MobileNetV2, VGG19, DenseNet121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Helper Functions & Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **This section to define all Helper functions through the notebook and any hyperparameters used later for training the models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:07:55.954406Z",
     "iopub.status.busy": "2023-12-19T01:07:55.953953Z",
     "iopub.status.idle": "2023-12-19T01:07:55.966714Z",
     "shell.execute_reply": "2023-12-19T01:07:55.965647Z",
     "shell.execute_reply.started": "2023-12-19T01:07:55.954358Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def directory_to_df(path : str):\n",
    "    \"\"\"\n",
    "    This function to retrieve all images from targeted folder in a file, the\n",
    "    folder must be divided hirarchally in which each class contains its images individually.\n",
    "    ________________________________________________________________________________________________\n",
    "    Arguments-\n",
    "    \n",
    "    path: String -> the main folder directory that contains train/test folders\n",
    "    \n",
    "    ________________________________________________________________________________________________\n",
    "    Return-\n",
    "    \n",
    "    DataFrame: contains the images path and label corresponding to every image\n",
    "    \"\"\"\n",
    "    df = []\n",
    "    chars = 'abcdefghijklmnopqrstuvwxyz'    # to include lowercase letters only\n",
    "    for cls in os.listdir(path):\n",
    "        cls_path = os.path.join(path,cls)\n",
    "        cls_name = cls.split('_')[0]\n",
    "        if not cls_name in chars:\n",
    "            continue\n",
    "        for img_path in os.listdir(cls_path):\n",
    "            direct = os.path.join(cls_path,img_path)\n",
    "            df.append([direct,cls_name])\n",
    "    \n",
    "    df = pd.DataFrame(df, columns=['image','label'])\n",
    "    print(\"The number of samples found:\",len(df))\n",
    "    return df.copy()\n",
    "\n",
    "def read_image(path):\n",
    "    \"\"\"\n",
    "    Read an image from specified directory\n",
    "    _____________________________________________________________\n",
    "    Arguments:\n",
    "    \n",
    "    path: String -> a directory of the image\n",
    "    _____________________________________________________________\n",
    "    Return:\n",
    "    \n",
    "    image: numpy.array of the image\n",
    "    \"\"\"\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "def show_image(img, label=None) -> None:\n",
    "    \"\"\"\n",
    "    This function to display any image\n",
    "    _________________________________________________________\n",
    "    Arguements:\n",
    "    \n",
    "    img: numpy.array of N-D\n",
    "    \n",
    "    label: String -> the title/label added with the image, Default= None\n",
    "    _________________________________________________________\n",
    "    Return:\n",
    "    \n",
    "    plt.imshow()\n",
    "    \"\"\"\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis(False)\n",
    "    plt.title(label)\n",
    "    plt.show()\n",
    "    \n",
    "def clbck(model_name):\n",
    "    # The function is defined to make the callbacks for training the models\n",
    "    ERLY = EarlyStopping(patience=10, min_delta=0.01, start_from_epoch=10, verbose=1)\n",
    "    RD = ReduceLROnPlateau(patience=5, min_delta=0.01, factor=0.5)\n",
    "    CHK = ModelCheckpoint(f'{model_name}_model.keras',verbose=1, save_best_only=True)\n",
    "    return [ERLY,RD,CHK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T02:55:15.66325Z",
     "iopub.status.busy": "2023-12-19T02:55:15.662858Z",
     "iopub.status.idle": "2023-12-19T02:55:15.670866Z",
     "shell.execute_reply": "2023-12-19T02:55:15.669775Z",
     "shell.execute_reply.started": "2023-12-19T02:55:15.663217Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Pre-defined hyperparameters\n",
    "IMG_SHAPE = (32,32)\n",
    "IMG_SIZE = (32,32,3)\n",
    "BATCH_SIZE = 32\n",
    "opt = Adam(learning_rate=0.00001, epsilon=1e-6)\n",
    "loss = 'categorical_crossentropy'\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x221a3dfa440>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.get_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11747330776655770565\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPUs found\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.set_visible_devices(physical_devices[0], 'GPU')  # Set first GPU as visible\n",
    "    print(f\"Using GPU: {physical_devices[0]}\")\n",
    "else:\n",
    "    print(\"No GPUs found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x221a3dfa440>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.get_default_graph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Reading & preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T21:32:54.867778Z",
     "iopub.status.busy": "2023-12-18T21:32:54.866951Z",
     "iopub.status.idle": "2023-12-18T21:33:03.258053Z",
     "shell.execute_reply": "2023-12-18T21:33:03.257023Z",
     "shell.execute_reply.started": "2023-12-18T21:32:54.867747Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples found: 85199\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset\\a_L\\A_L_1.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset\\a_L\\A_L_10.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset\\a_L\\A_L_100.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset\\a_L\\A_L_1000.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset\\a_L\\A_L_1001.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      image label\n",
       "0     dataset\\a_L\\A_L_1.png     a\n",
       "1    dataset\\a_L\\A_L_10.png     a\n",
       "2   dataset\\a_L\\A_L_100.png     a\n",
       "3  dataset\\a_L\\A_L_1000.png     a\n",
       "4  dataset\\a_L\\A_L_1001.png     a"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the dataset in dataframe \n",
    "main_path = 'dataset'\n",
    "df = directory_to_df(main_path)                   # convert the dataset into df of two columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T21:33:03.260114Z",
     "iopub.status.busy": "2023-12-18T21:33:03.259707Z",
     "iopub.status.idle": "2023-12-18T21:33:03.284837Z",
     "shell.execute_reply": "2023-12-18T21:33:03.28387Z",
     "shell.execute_reply.started": "2023-12-18T21:33:03.260069Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "e    3284\n",
       "r    3284\n",
       "n    3281\n",
       "m    3281\n",
       "a    3281\n",
       "q    3279\n",
       "u    3278\n",
       "i    3277\n",
       "d    3277\n",
       "k    3276\n",
       "y    3276\n",
       "x    3276\n",
       "t    3276\n",
       "l    3276\n",
       "s    3276\n",
       "h    3275\n",
       "f    3275\n",
       "g    3275\n",
       "o    3275\n",
       "w    3275\n",
       "z    3275\n",
       "p    3275\n",
       "j    3274\n",
       "c    3274\n",
       "b    3274\n",
       "v    3274\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Splitting the dataframe\n",
    "- The dataframe is splitted to get 70% of the dataset for `training` , and 30% for `testing`\n",
    "- The training set is splitted into `training` and `validation` to enhance the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T21:33:03.286356Z",
     "iopub.status.busy": "2023-12-18T21:33:03.286015Z",
     "iopub.status.idle": "2023-12-18T21:33:03.309967Z",
     "shell.execute_reply": "2023-12-18T21:33:03.309266Z",
     "shell.execute_reply.started": "2023-12-18T21:33:03.286322Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Splitting for training & testing (70,30 respectively)\n",
    "X, y = df['image'], df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y , test_size=0.30, random_state=41)\n",
    "training_df = pd.concat((X_train,y_train), axis=1)\n",
    "testing_df = pd.concat((X_test,y_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T21:33:09.159434Z",
     "iopub.status.busy": "2023-12-18T21:33:09.158511Z",
     "iopub.status.idle": "2023-12-18T21:33:09.183644Z",
     "shell.execute_reply": "2023-12-18T21:33:09.182662Z",
     "shell.execute_reply.started": "2023-12-18T21:33:09.159388Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Splitting for training & validation (75,25 respectively) -> the training set size = 52.5%\n",
    "X, y = training_df['image'], training_df['label']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y , test_size=0.25, random_state=41)\n",
    "training_df = pd.concat((X_train,y_train), axis=1)\n",
    "validation_df = pd.concat((X_valid,y_valid), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Creating generators\n",
    "- The `ImageDataGenerators` is used for data augmentation, the augmentation is required since the `OCR` can work with different brightness which is not included in the dataset.\n",
    "- Also, it enhance the RAM usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T21:33:10.964244Z",
     "iopub.status.busy": "2023-12-18T21:33:10.963854Z",
     "iopub.status.idle": "2023-12-18T21:35:28.787249Z",
     "shell.execute_reply": "2023-12-18T21:35:28.786267Z",
     "shell.execute_reply.started": "2023-12-18T21:33:10.964213Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44729 validated image filenames belonging to 26 classes.\n",
      "Found 14910 validated image filenames belonging to 26 classes.\n",
      "Found 25560 validated image filenames belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "# Creating generators\n",
    "gen = ImageDataGenerator(dtype=np.int32, brightness_range=[0.0,1.0], fill_mode='nearest')\n",
    "gen2 = ImageDataGenerator(dtype=np.int32, fill_mode='nearest')\n",
    "train_gen = gen.flow_from_dataframe(training_df, x_col='image',y_col='label', batch_size=BATCH_SIZE, \n",
    "                                   target_size=IMG_SHAPE)\n",
    "valid_gen = gen2.flow_from_dataframe(validation_df, x_col='image', y_col='label', batch_size=BATCH_SIZE, \n",
    "                                        target_size=IMG_SHAPE, shuffle=False)\n",
    "test_gen = gen2.flow_from_dataframe(testing_df, x_col='image', y_col='label', batch_size=BATCH_SIZE, \n",
    "                                       target_size=IMG_SHAPE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T21:35:35.56711Z",
     "iopub.status.busy": "2023-12-18T21:35:35.566729Z",
     "iopub.status.idle": "2023-12-18T21:35:35.572182Z",
     "shell.execute_reply": "2023-12-18T21:35:35.571118Z",
     "shell.execute_reply.started": "2023-12-18T21:35:35.567072Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Making a mapping of the classes and the inverse for later processings\n",
    "mapping = train_gen.class_indices\n",
    "mapping_inverse = dict(map(lambda x: tuple(reversed(x)), mapping.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:15:48.268488Z",
     "iopub.status.busy": "2023-12-19T01:15:48.267759Z",
     "iopub.status.idle": "2023-12-19T01:15:48.565776Z",
     "shell.execute_reply": "2023-12-19T01:15:48.564786Z",
     "shell.execute_reply.started": "2023-12-19T01:15:48.268456Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the image: (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Reading a sample from the dataset\n",
    "BATCH_NUM = 10\n",
    "IMG_NUM = 2      # from 0 to 31\n",
    "show_image(train_gen[BATCH_NUM][0][IMG_NUM],mapping_inverse[train_gen[BATCH_NUM][1][IMG_NUM].argmax()])\n",
    "print('The shape of the image:',train_gen[BATCH_NUM][0][IMG_NUM].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:16:07.732523Z",
     "iopub.status.busy": "2023-12-19T01:16:07.731829Z",
     "iopub.status.idle": "2023-12-19T01:16:08.007994Z",
     "shell.execute_reply": "2023-12-19T01:16:08.006845Z",
     "shell.execute_reply.started": "2023-12-19T01:16:07.732491Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the image: (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Reading another sample from the dataset\n",
    "BATCH_NUM = 65\n",
    "IMG_NUM = 30      # from 0 to 31\n",
    "show_image(train_gen[BATCH_NUM][0][IMG_NUM],mapping_inverse[train_gen[BATCH_NUM][1][IMG_NUM].argmax()])\n",
    "print('The shape of the image:',train_gen[BATCH_NUM][0][IMG_NUM].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Modeling\n",
    "*Our target is to build a **`custom CNN model`** to train on our targeted images for the `OCR` application. in advance, we also will use 4 Pre-trained models as part of `Transfer Learning` and to enhance the performance of the application.*\n",
    "\n",
    "***Our targeted pretrained models are the following:***\n",
    "\n",
    "*- EfficientNetB7*\n",
    "\n",
    "*- MobileNetV2*\n",
    "\n",
    "*- VGG19*\n",
    "\n",
    "*- DenseNet121*\n",
    "\n",
    "***The fine-tuning strategy:*** *using a small value of `LR` of the optimizer `Adam` will make an efficient use of the pre-trained models on our dataset without **FREEZING** the input layers in which better performance is required in our case*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1) Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:23:51.274103Z",
     "iopub.status.busy": "2023-12-19T01:23:51.273737Z",
     "iopub.status.idle": "2023-12-19T01:23:51.387886Z",
     "shell.execute_reply": "2023-12-19T01:23:51.387105Z",
     "shell.execute_reply.started": "2023-12-19T01:23:51.274073Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom CNN\n",
    "CNN_model = Sequential()\n",
    "CNN_model.add(Input(shape=IMG_SIZE, batch_size=BATCH_SIZE, name='Input'))\n",
    "CNN_model.add(Conv2D(3, (3,3), strides=1, activation='relu', padding='same'))\n",
    "CNN_model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "CNN_model.add(MaxPool2D((3,3)))\n",
    "CNN_model.add(Conv2D(256, (3,3), activation='relu'))\n",
    "CNN_model.add(Dropout(0.2))\n",
    "CNN_model.add(Conv2D(256, (3,3), strides=2, activation='relu', padding='same'))\n",
    "CNN_model.add(MaxPool2D((2,2)))\n",
    "CNN_model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "CNN_model.add(Dropout(0.2))\n",
    "CNN_model.add(Conv2D(1024, (2,2), activation='relu', padding='same'))\n",
    "CNN_model.add(MaxPool2D(2,2))\n",
    "CNN_model.add(Flatten())\n",
    "CNN_model.add(Dense(1024, activation='selu'))\n",
    "CNN_model.add(Dense(len(mapping), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:23:51.793129Z",
     "iopub.status.busy": "2023-12-19T01:23:51.79275Z",
     "iopub.status.idle": "2023-12-19T01:23:51.833224Z",
     "shell.execute_reply": "2023-12-19T01:23:51.832395Z",
     "shell.execute_reply.started": "2023-12-19T01:23:51.793097Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)               │        <span style=\"color: #00af00; text-decoration-color: #00af00\">26,650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)        │            \u001b[38;5;34m84\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m3,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             │     \u001b[38;5;34m1,049,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m26\u001b[0m)               │        \u001b[38;5;34m26,650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,243,502</span> (20.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,243,502\u001b[0m (20.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,243,502</span> (20.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,243,502\u001b[0m (20.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CNN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:24:59.139997Z",
     "iopub.status.busy": "2023-12-19T01:24:59.139604Z",
     "iopub.status.idle": "2023-12-19T01:24:59.152495Z",
     "shell.execute_reply": "2023-12-19T01:24:59.151648Z",
     "shell.execute_reply.started": "2023-12-19T01:24:59.139966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Default parameters of adam will be used for the custom CNN\n",
    "CNN_model.compile(optimizer=Adam(), loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:26:15.114725Z",
     "iopub.status.busy": "2023-12-19T01:26:15.114341Z",
     "iopub.status.idle": "2023-12-19T01:47:31.160749Z",
     "shell.execute_reply": "2023-12-19T01:47:31.159948Z",
     "shell.execute_reply.started": "2023-12-19T01:26:15.114696Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\Seimbang.in\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.5119 - loss: 1.8173\n",
      "Epoch 1: val_loss improved from inf to 0.49231, saving model to CustomCnn_model.keras\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 390ms/step - accuracy: 0.5120 - loss: 1.8168 - val_accuracy: 0.8818 - val_loss: 0.4923 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.8793 - loss: 0.4320\n",
      "Epoch 2: val_loss did not improve from 0.49231\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 228ms/step - accuracy: 0.8793 - loss: 0.4320 - val_accuracy: 0.8814 - val_loss: 0.5747 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8952 - loss: 0.3821\n",
      "Epoch 3: val_loss improved from 0.49231 to 0.30354, saving model to CustomCnn_model.keras\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 383ms/step - accuracy: 0.8952 - loss: 0.3821 - val_accuracy: 0.9203 - val_loss: 0.3035 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.9171 - loss: 0.3057\n",
      "Epoch 4: val_loss did not improve from 0.30354\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m580s\u001b[0m 415ms/step - accuracy: 0.9171 - loss: 0.3057 - val_accuracy: 0.9227 - val_loss: 0.3166 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9156 - loss: 0.3135\n",
      "Epoch 5: val_loss improved from 0.30354 to 0.27788, saving model to CustomCnn_model.keras\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 363ms/step - accuracy: 0.9156 - loss: 0.3135 - val_accuracy: 0.9289 - val_loss: 0.2779 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.9225 - loss: 0.2834\n",
      "Epoch 6: val_loss did not improve from 0.27788\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m670s\u001b[0m 480ms/step - accuracy: 0.9225 - loss: 0.2835 - val_accuracy: 0.9270 - val_loss: 0.3254 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - accuracy: 0.9249 - loss: 0.2864\n",
      "Epoch 7: val_loss did not improve from 0.27788\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m756s\u001b[0m 541ms/step - accuracy: 0.9249 - loss: 0.2865 - val_accuracy: 0.7447 - val_loss: 1.5292 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.8793 - loss: 0.4927\n",
      "Epoch 8: val_loss did not improve from 0.27788\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 344ms/step - accuracy: 0.8793 - loss: 0.4926 - val_accuracy: 0.9333 - val_loss: 0.3192 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739ms/step - accuracy: 0.9341 - loss: 0.2448\n",
      "Epoch 9: val_loss did not improve from 0.27788\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1040s\u001b[0m 744ms/step - accuracy: 0.9341 - loss: 0.2449 - val_accuracy: 0.9276 - val_loss: 0.3724 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9261 - loss: 0.2950\n",
      "Epoch 10: val_loss did not improve from 0.27788\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 86ms/step - accuracy: 0.9261 - loss: 0.2950 - val_accuracy: 0.9326 - val_loss: 0.2998 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.9502 - loss: 0.1820"
     ]
    }
   ],
   "source": [
    "# different num. of epochs will be given for better convergence for the Custom CNN\n",
    "history = CNN_model.fit(train_gen, epochs=20, validation_data=valid_gen, callbacks=clbck(\"CustomCnn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:47:31.162891Z",
     "iopub.status.busy": "2023-12-19T01:47:31.162591Z",
     "iopub.status.idle": "2023-12-19T01:47:31.409636Z",
     "shell.execute_reply": "2023-12-19T01:47:31.40879Z",
     "shell.execute_reply.started": "2023-12-19T01:47:31.162865Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss value')\n",
    "plt.title(\"Custom CNN Training VS. Validation performance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:47:31.41092Z",
     "iopub.status.busy": "2023-12-19T01:47:31.410671Z",
     "iopub.status.idle": "2023-12-19T01:48:18.200732Z",
     "shell.execute_reply": "2023-12-19T01:48:18.199734Z",
     "shell.execute_reply.started": "2023-12-19T01:47:31.410898Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Making a prediction out of the Custom CNN for the testing set for the evaluation\n",
    "prediction = CNN_model.predict(test_gen)\n",
    "pred = list(map(lambda x: mapping_inverse[np.argmax(x)], prediction))\n",
    "y_test = list(map(lambda x: mapping_inverse[x],test_gen.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:48:18.203256Z",
     "iopub.status.busy": "2023-12-19T01:48:18.202934Z",
     "iopub.status.idle": "2023-12-19T01:48:18.488257Z",
     "shell.execute_reply": "2023-12-19T01:48:18.487298Z",
     "shell.execute_reply.started": "2023-12-19T01:48:18.203228Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('\\t\\tThe Custom CNN Evaluation Performance')\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2) EfficientNetB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:48:18.48989Z",
     "iopub.status.busy": "2023-12-19T01:48:18.489531Z",
     "iopub.status.idle": "2023-12-19T01:48:30.904917Z",
     "shell.execute_reply": "2023-12-19T01:48:30.903833Z",
     "shell.execute_reply.started": "2023-12-19T01:48:18.489855Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# EfficientNetB7 input layers will not be FREEZED\n",
    "train_layers = EfficientNetB7(include_top=False, input_shape=IMG_SIZE)\n",
    "EffNetB7 = Sequential()\n",
    "EffNetB7.add(train_layers)\n",
    "EffNetB7.add(Flatten())\n",
    "EffNetB7.add(Dense(1024, activation='selu'))\n",
    "EffNetB7.add(Dropout(0.2))\n",
    "EffNetB7.add(Dense(512, activation='selu'))\n",
    "EffNetB7.add(Dense(len(mapping), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:48:30.906641Z",
     "iopub.status.busy": "2023-12-19T01:48:30.90632Z",
     "iopub.status.idle": "2023-12-19T01:48:31.001118Z",
     "shell.execute_reply": "2023-12-19T01:48:31.000247Z",
     "shell.execute_reply.started": "2023-12-19T01:48:30.906615Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EffNetB7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:48:47.684019Z",
     "iopub.status.busy": "2023-12-19T01:48:47.68313Z",
     "iopub.status.idle": "2023-12-19T01:48:47.71204Z",
     "shell.execute_reply": "2023-12-19T01:48:47.711255Z",
     "shell.execute_reply.started": "2023-12-19T01:48:47.683984Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# The pre-defined optimizer will be used with too small learning rate\n",
    "EffNetB7.compile(optimizer=opt, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:49:08.110172Z",
     "iopub.status.busy": "2023-12-19T01:49:08.109766Z",
     "iopub.status.idle": "2023-12-19T02:27:39.428156Z",
     "shell.execute_reply": "2023-12-19T02:27:39.427122Z",
     "shell.execute_reply.started": "2023-12-19T01:49:08.110141Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history2 = EffNetB7.fit(train_gen, epochs=EPOCHS, validation_data=valid_gen, callbacks=clbck(\"EfficientNetB7\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T02:28:26.613443Z",
     "iopub.status.busy": "2023-12-19T02:28:26.613117Z",
     "iopub.status.idle": "2023-12-19T02:28:26.8454Z",
     "shell.execute_reply": "2023-12-19T02:28:26.844514Z",
     "shell.execute_reply.started": "2023-12-19T02:28:26.613419Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history2.history['loss'], label='Training loss')\n",
    "plt.plot(history2.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss value')\n",
    "plt.title(\"EfficientNetB7 Training VS. Validation performance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T02:29:03.877432Z",
     "iopub.status.busy": "2023-12-19T02:29:03.876537Z",
     "iopub.status.idle": "2023-12-19T02:29:59.308389Z",
     "shell.execute_reply": "2023-12-19T02:29:59.307573Z",
     "shell.execute_reply.started": "2023-12-19T02:29:03.877389Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Making a prediction out of the EfficientNetB7 for the testing set for the evaluation\n",
    "prediction = EffNetB7.predict(test_gen)\n",
    "pred = list(map(lambda x: mapping_inverse[np.argmax(x)], prediction))\n",
    "y_test = list(map(lambda x: mapping_inverse[x],test_gen.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T02:32:02.690807Z",
     "iopub.status.busy": "2023-12-19T02:32:02.690344Z",
     "iopub.status.idle": "2023-12-19T02:32:02.976005Z",
     "shell.execute_reply": "2023-12-19T02:32:02.975099Z",
     "shell.execute_reply.started": "2023-12-19T02:32:02.690779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('\\t     The EfficientNetB7 Evaluation Performance')\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3) MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T02:34:47.378097Z",
     "iopub.status.busy": "2023-12-19T02:34:47.377299Z",
     "iopub.status.idle": "2023-12-19T02:34:49.186317Z",
     "shell.execute_reply": "2023-12-19T02:34:49.185115Z",
     "shell.execute_reply.started": "2023-12-19T02:34:47.378042Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# MobileNetV2 input layers will not be FREEZED\n",
    "train_layers = MobileNetV2(include_top=False, input_shape=IMG_SIZE)\n",
    "MobNetV2 = Sequential()\n",
    "MobNetV2.add(train_layers)\n",
    "MobNetV2.add(Flatten())\n",
    "MobNetV2.add(Dense(1024, activation='selu'))\n",
    "MobNetV2.add(Dropout(0.2))\n",
    "MobNetV2.add(Dense(512, activation='selu'))\n",
    "MobNetV2.add(Dense(len(mapping), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T02:34:49.189004Z",
     "iopub.status.busy": "2023-12-19T02:34:49.188324Z",
     "iopub.status.idle": "2023-12-19T02:34:49.233165Z",
     "shell.execute_reply": "2023-12-19T02:34:49.232307Z",
     "shell.execute_reply.started": "2023-12-19T02:34:49.188966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MobNetV2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T02:35:28.067275Z",
     "iopub.status.busy": "2023-12-19T02:35:28.066863Z",
     "iopub.status.idle": "2023-12-19T02:35:28.082904Z",
     "shell.execute_reply": "2023-12-19T02:35:28.08186Z",
     "shell.execute_reply.started": "2023-12-19T02:35:28.067241Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MobNetV2.compile(optimizer=opt, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T02:35:28.490722Z",
     "iopub.status.busy": "2023-12-19T02:35:28.489815Z",
     "iopub.status.idle": "2023-12-19T02:48:03.39111Z",
     "shell.execute_reply": "2023-12-19T02:48:03.390232Z",
     "shell.execute_reply.started": "2023-12-19T02:35:28.490684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history3 = MobNetV2.fit(train_gen, epochs=EPOCHS, validation_data=valid_gen, callbacks=clbck('MobileNetV2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T02:48:39.732512Z",
     "iopub.status.busy": "2023-12-19T02:48:39.732117Z",
     "iopub.status.idle": "2023-12-19T02:48:40.034029Z",
     "shell.execute_reply": "2023-12-19T02:48:40.033094Z",
     "shell.execute_reply.started": "2023-12-19T02:48:39.732479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history3.history['loss'], label='Training loss')\n",
    "plt.plot(history3.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss value')\n",
    "plt.title(\"MobileNetV2 Training VS. Validation performance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T02:48:57.428818Z",
     "iopub.status.busy": "2023-12-19T02:48:57.42788Z",
     "iopub.status.idle": "2023-12-19T02:49:47.60332Z",
     "shell.execute_reply": "2023-12-19T02:49:47.602252Z",
     "shell.execute_reply.started": "2023-12-19T02:48:57.428777Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Making a prediction out of the MobileNetV2 for the testing set for the evaluation\n",
    "prediction = MobNetV2.predict(test_gen)\n",
    "pred = list(map(lambda x: mapping_inverse[np.argmax(x)], prediction))\n",
    "y_test = list(map(lambda x: mapping_inverse[x],test_gen.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T02:49:48.045726Z",
     "iopub.status.busy": "2023-12-19T02:49:48.045361Z",
     "iopub.status.idle": "2023-12-19T02:49:48.326394Z",
     "shell.execute_reply": "2023-12-19T02:49:48.325508Z",
     "shell.execute_reply.started": "2023-12-19T02:49:48.045699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('\\t     The MobileNetV2 Evaluation Performance')\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4) VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T02:54:33.787935Z",
     "iopub.status.busy": "2023-12-19T02:54:33.787573Z",
     "iopub.status.idle": "2023-12-19T02:54:34.318112Z",
     "shell.execute_reply": "2023-12-19T02:54:34.317281Z",
     "shell.execute_reply.started": "2023-12-19T02:54:33.787906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# VGG19 input layers will not be FREEZED\n",
    "train_layers = VGG19(include_top=False, input_shape=IMG_SIZE)\n",
    "VG = Sequential()\n",
    "VG.add(train_layers)\n",
    "VG.add(Flatten())\n",
    "VG.add(Dense(1024, activation='selu'))\n",
    "VG.add(Dense(512, activation='selu'))\n",
    "VG.add(Dense(len(mapping), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T02:54:43.815969Z",
     "iopub.status.busy": "2023-12-19T02:54:43.81561Z",
     "iopub.status.idle": "2023-12-19T02:54:43.837735Z",
     "shell.execute_reply": "2023-12-19T02:54:43.836877Z",
     "shell.execute_reply.started": "2023-12-19T02:54:43.815941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "VG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T02:55:21.803765Z",
     "iopub.status.busy": "2023-12-19T02:55:21.802915Z",
     "iopub.status.idle": "2023-12-19T02:55:21.814725Z",
     "shell.execute_reply": "2023-12-19T02:55:21.813878Z",
     "shell.execute_reply.started": "2023-12-19T02:55:21.803733Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "VG.compile(optimizer=opt, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T02:55:22.433444Z",
     "iopub.status.busy": "2023-12-19T02:55:22.432742Z",
     "iopub.status.idle": "2023-12-19T03:06:45.418032Z",
     "shell.execute_reply": "2023-12-19T03:06:45.417222Z",
     "shell.execute_reply.started": "2023-12-19T02:55:22.433405Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history4 = VG.fit(train_gen, validation_data=valid_gen, epochs=EPOCHS, callbacks=clbck('VGG19'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T03:06:59.224191Z",
     "iopub.status.busy": "2023-12-19T03:06:59.223442Z",
     "iopub.status.idle": "2023-12-19T03:06:59.492313Z",
     "shell.execute_reply": "2023-12-19T03:06:59.491424Z",
     "shell.execute_reply.started": "2023-12-19T03:06:59.224158Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history4.history['loss'], label='Training loss')\n",
    "plt.plot(history4.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss value')\n",
    "plt.title(\"VGG19 Training VS. Validation performance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T03:07:09.379456Z",
     "iopub.status.busy": "2023-12-19T03:07:09.378862Z",
     "iopub.status.idle": "2023-12-19T03:07:57.217521Z",
     "shell.execute_reply": "2023-12-19T03:07:57.216625Z",
     "shell.execute_reply.started": "2023-12-19T03:07:09.379406Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Making a prediction out of the VGG19 for the testing set for the evaluation\n",
    "prediction = VG.predict(test_gen)\n",
    "pred = list(map(lambda x: mapping_inverse[np.argmax(x)], prediction))\n",
    "y_test = list(map(lambda x: mapping_inverse[x],test_gen.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T03:08:21.985452Z",
     "iopub.status.busy": "2023-12-19T03:08:21.984662Z",
     "iopub.status.idle": "2023-12-19T03:08:22.26828Z",
     "shell.execute_reply": "2023-12-19T03:08:22.267362Z",
     "shell.execute_reply.started": "2023-12-19T03:08:21.985415Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('\\t\\tThe VGG19 Evaluation Performance')\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5) DenseNet121 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T21:36:05.012496Z",
     "iopub.status.busy": "2023-12-18T21:36:05.012134Z",
     "iopub.status.idle": "2023-12-18T21:36:10.229954Z",
     "shell.execute_reply": "2023-12-18T21:36:10.229121Z",
     "shell.execute_reply.started": "2023-12-18T21:36:05.012469Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# DenseNset121 input layers will not be FREEZED\n",
    "train_layers = DenseNet121(include_top=False, input_shape=IMG_SIZE)\n",
    "Den = Sequential()\n",
    "Den.add(train_layers)\n",
    "Den.add(Flatten())\n",
    "Den.add(Dense(1024, activation='selu'))\n",
    "Den.add(Dense(512, activation='selu'))\n",
    "Den.add(Dense(len(mapping), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T21:36:10.231842Z",
     "iopub.status.busy": "2023-12-18T21:36:10.231517Z",
     "iopub.status.idle": "2023-12-18T21:36:10.295818Z",
     "shell.execute_reply": "2023-12-18T21:36:10.295112Z",
     "shell.execute_reply.started": "2023-12-18T21:36:10.231814Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Den.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T21:36:12.209916Z",
     "iopub.status.busy": "2023-12-18T21:36:12.209454Z",
     "iopub.status.idle": "2023-12-18T21:36:12.2359Z",
     "shell.execute_reply": "2023-12-18T21:36:12.234981Z",
     "shell.execute_reply.started": "2023-12-18T21:36:12.209878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Den.compile(optimizer=opt, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T21:36:14.019318Z",
     "iopub.status.busy": "2023-12-18T21:36:14.018539Z",
     "iopub.status.idle": "2023-12-18T21:59:54.600454Z",
     "shell.execute_reply": "2023-12-18T21:59:54.599591Z",
     "shell.execute_reply.started": "2023-12-18T21:36:14.019281Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history5 = Den.fit(train_gen, validation_data=valid_gen, epochs=10, callbacks=clbck(\"DenseNet121\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:00:05.291487Z",
     "iopub.status.busy": "2023-12-18T22:00:05.290753Z",
     "iopub.status.idle": "2023-12-18T22:00:05.523785Z",
     "shell.execute_reply": "2023-12-18T22:00:05.522865Z",
     "shell.execute_reply.started": "2023-12-18T22:00:05.291457Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history5.history['loss'], label='Training loss')\n",
    "plt.plot(history5.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss value')\n",
    "plt.title(\"DenseNet121 Training VS. Validation performance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T03:10:41.677906Z",
     "iopub.status.busy": "2023-12-19T03:10:41.677155Z",
     "iopub.status.idle": "2023-12-19T03:11:05.869647Z",
     "shell.execute_reply": "2023-12-19T03:11:05.868788Z",
     "shell.execute_reply.started": "2023-12-19T03:10:41.677873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Making a prediction out of the DenseNet121 for the testing set for the evaluation\n",
    "prediction = Den.predict(test_gen)\n",
    "pred = list(map(lambda x: mapping_inverse[np.argmax(x)], prediction))\n",
    "y_test = list(map(lambda x: mapping_inverse[x],test_gen.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T03:11:32.363346Z",
     "iopub.status.busy": "2023-12-19T03:11:32.362628Z",
     "iopub.status.idle": "2023-12-19T03:11:32.644801Z",
     "shell.execute_reply": "2023-12-19T03:11:32.643832Z",
     "shell.execute_reply.started": "2023-12-19T03:11:32.363311Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('\\t\\tThe DenseNet121 Evaluation Performance')\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Evaluation & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T03:17:17.414201Z",
     "iopub.status.busy": "2023-12-19T03:17:17.413462Z",
     "iopub.status.idle": "2023-12-19T03:17:17.42468Z",
     "shell.execute_reply": "2023-12-19T03:17:17.42364Z",
     "shell.execute_reply.started": "2023-12-19T03:17:17.414168Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vals = {'accuracy':[0.95,0.93,0.71,0.96,0.95], 'precision':[0.96,0.94,0.72,0.96,0.95],\n",
    "       'recall':[0.95,0.93,0.71,0.96,0.95], 'F1-Score':[0.95,0.93,0.71,0.96,0.95]}\n",
    "results = pd.DataFrame(vals, index=['Custom CNN','EfficientNetB7','MobileNetV7','VGG19',\n",
    "                                   'DenseNet121'])\n",
    "\n",
    "print(\"\\t\\tThe Evaluation results of CNN/Pre-trained models\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T03:17:35.47788Z",
     "iopub.status.busy": "2023-12-19T03:17:35.477516Z",
     "iopub.status.idle": "2023-12-19T03:17:35.735343Z",
     "shell.execute_reply": "2023-12-19T03:17:35.734386Z",
     "shell.execute_reply.started": "2023-12-19T03:17:35.477849Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=results, x=results.index, y='accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Models')\n",
    "plt.title(\"Models Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T03:17:47.699688Z",
     "iopub.status.busy": "2023-12-19T03:17:47.699301Z",
     "iopub.status.idle": "2023-12-19T03:17:47.958616Z",
     "shell.execute_reply": "2023-12-19T03:17:47.957727Z",
     "shell.execute_reply.started": "2023-12-19T03:17:47.699656Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=results, x=results.index, y='precision')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Models')\n",
    "plt.title(\"Models Precision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T03:18:04.001432Z",
     "iopub.status.busy": "2023-12-19T03:18:04.001023Z",
     "iopub.status.idle": "2023-12-19T03:18:04.269453Z",
     "shell.execute_reply": "2023-12-19T03:18:04.268493Z",
     "shell.execute_reply.started": "2023-12-19T03:18:04.0014Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=results, x=results.index, y='recall')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Models')\n",
    "plt.title(\"Models Recall\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T03:18:11.536261Z",
     "iopub.status.busy": "2023-12-19T03:18:11.535433Z",
     "iopub.status.idle": "2023-12-19T03:18:11.72862Z",
     "shell.execute_reply": "2023-12-19T03:18:11.72769Z",
     "shell.execute_reply.started": "2023-12-19T03:18:11.536225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=results, x=results.index, y='F1-Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Models')\n",
    "plt.title(\"Models F1-Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Post-Processing\n",
    "#### **THIS SECTION IS ABOUT `Computer Vision` TECHNIQUES**\n",
    "\n",
    "*the image will be taken from the user/externally to be processed and input into our model. some **LOW LEVEL COMPUTER VISION TECHNIQUES** are used in order to enhance the input image, wheter it is text or handwritten, these techniques are the following:*\n",
    "\n",
    "- **Binarization:** The binarization function applies Otsu's binarization to the grayscale image, producing a binary image.\n",
    "\n",
    "- **Dilate:** The dilate function performs morphological dilation on the binary image. The degree of dilation is adjusted based on whether processing `words` or `characters`.\n",
    "\n",
    "- **Find Rectangles:** The find_rect function identifies bounding rectangles in the binary image, sorting them based on their **x-coordinate (From Left-to-Right)**.\n",
    "\n",
    "- **Extract Characters:** The extract function uses the aforementioned techniques to extract characters from the image. It identifies words **FIRST**, then extracts characters from each word, and with the use of the pre-trained deep learning model to recognize each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T03:49:30.064185Z",
     "iopub.status.busy": "2023-12-19T03:49:30.063771Z",
     "iopub.status.idle": "2023-12-19T03:49:30.082173Z",
     "shell.execute_reply": "2023-12-19T03:49:30.081229Z",
     "shell.execute_reply.started": "2023-12-19T03:49:30.064153Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Computer Vision - Low level techniques\n",
    "def load_model():\n",
    "    model_path = 'DenseNet121_model.keras'\n",
    "    model = tf.keras.saving.load_model(model_path)\n",
    "    return model\n",
    "\n",
    "def convert_2_gray(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    return gray_image\n",
    "\n",
    "def binarization(image):\n",
    "    img, thresh = cv2.threshold(image, 0,255, cv2.THRESH_OTSU|cv2.THRESH_BINARY_INV)\n",
    "    return img, thresh\n",
    "\n",
    "def dilate(image, words= False):\n",
    "    img = image.copy()\n",
    "    m = 3\n",
    "    n = m - 2                   # n less than m for Vertical structuring element to dilate chars\n",
    "    itrs = 4\n",
    "    if words:\n",
    "        m = 6\n",
    "        n = m\n",
    "        itrs = 3\n",
    "    rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (n, m))\n",
    "    dilation = cv2.dilate(img, rect_kernel, iterations = itrs)\n",
    "    return dilation\n",
    "\n",
    "def find_rect(image):\n",
    "    contours, hierarchy = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    rects = []\n",
    "    \n",
    "    for cnt in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)  # Extract the bounding rectangle coordinates of each countour\n",
    "        rects.append([x,y,w,h])\n",
    "        \n",
    "    sorted_rects = list(sorted(rects, key=lambda x: x[0])) # Sorting the rects from Left-to-Right\n",
    "    return sorted_rects\n",
    "\n",
    "def extract(image):\n",
    "    model = load_model()\n",
    "    chars = []              # a list to store recognized characters\n",
    "    \n",
    "    image_cpy = image.copy()\n",
    "    _, bin_img = binarization(convert_2_gray(image_cpy))\n",
    "    full_dil_img = dilate(bin_img,words=True)\n",
    "    words = find_rect(full_dil_img)                       # Recognized words within the image \n",
    "    del _, bin_img, full_dil_img                          # for better memory usage\n",
    "    \n",
    "    for word in words:\n",
    "        x,y,w,h = word                                    # coordinates of the word\n",
    "        img = image_cpy[y:y+h, x:x+w]\n",
    "        \n",
    "        _, bin_img = binarization(convert_2_gray(img))\n",
    "        dil_img = dilate(bin_img)\n",
    "        char_parts = find_rect(dil_img)                     # Recognized chars withtin the word\n",
    "        cv2.rectangle(image, (x,y),(x+w,y+h), (0,255,0), 3) # draw a green rectangle around the word\n",
    "        \n",
    "        del _, bin_img, dil_img\n",
    "        \n",
    "        for char in char_parts:    \n",
    "            x,y,w,h = char\n",
    "            ch = img[y:y+h, x:x+w]\n",
    "            \n",
    "            empty_img = np.full((32,32,1),255, dtype=np.uint8) # a white image used for resize with filling\n",
    "            x,y = 3,3                                          # starting indecies\n",
    "            resized = cv2.resize(ch, (16,22), interpolation=cv2.INTER_CUBIC)\n",
    "            gray = convert_2_gray(resized)\n",
    "            empty_img[y:y+22, x:x+16,0] = gray.copy()          # integrate the recognized char into the white image\n",
    "            gray = cv2.cvtColor(empty_img, cv2.COLOR_GRAY2RGB)\n",
    "            gray = gray.astype(np.int32)\n",
    "            \n",
    "            predicted = mapping_inverse[np.argmax(model.predict(np.array([gray]), verbose=-1))]\n",
    "            chars.append(predicted)                            # append the character into the list\n",
    "            \n",
    "            del ch, resized, gray, empty_img\n",
    "        chars.append(' ')  # at the end of each iteration (end of word) append a space\n",
    "        \n",
    "    del model\n",
    "    show_image(image)\n",
    "    return ''.join(chars[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1) Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T03:47:17.727723Z",
     "iopub.status.busy": "2023-12-19T03:47:17.726843Z",
     "iopub.status.idle": "2023-12-19T03:47:27.256848Z",
     "shell.execute_reply": "2023-12-19T03:47:27.255624Z",
     "shell.execute_reply.started": "2023-12-19T03:47:17.727687Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Testing 1\n",
    "img = read_image('')\n",
    "text = extract(img)\n",
    "print('-->',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T03:49:34.17554Z",
     "iopub.status.busy": "2023-12-19T03:49:34.174736Z",
     "iopub.status.idle": "2023-12-19T03:49:42.519737Z",
     "shell.execute_reply": "2023-12-19T03:49:42.518801Z",
     "shell.execute_reply.started": "2023-12-19T03:49:34.175502Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Testing 2\n",
    "img2 = read_image('')\n",
    "text = extract(img2)\n",
    "print('-->',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T03:50:18.123588Z",
     "iopub.status.busy": "2023-12-19T03:50:18.123217Z",
     "iopub.status.idle": "2023-12-19T03:50:26.644924Z",
     "shell.execute_reply": "2023-12-19T03:50:26.642238Z",
     "shell.execute_reply.started": "2023-12-19T03:50:18.123556Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Testing 3\n",
    "img3 = read_image('')\n",
    "text = extract(img3)\n",
    "print('-->',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T03:51:21.797667Z",
     "iopub.status.busy": "2023-12-19T03:51:21.797267Z",
     "iopub.status.idle": "2023-12-19T03:51:31.348377Z",
     "shell.execute_reply": "2023-12-19T03:51:31.347044Z",
     "shell.execute_reply.started": "2023-12-19T03:51:21.797637Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Testing 4\n",
    "img4 = read_image('')\n",
    "text = extract(img4)\n",
    "print('-->',text)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1176843,
     "sourceId": 1972672,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1634134,
     "sourceId": 2685160,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3364134,
     "sourceId": 5850209,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4183058,
     "sourceId": 7225928,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4183087,
     "sourceId": 7225986,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4183132,
     "sourceId": 7226058,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4183218,
     "sourceId": 7226187,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4187890,
     "sourceId": 7232441,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4187993,
     "sourceId": 7232576,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4188664,
     "sourceId": 7233573,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4188689,
     "sourceId": 7233620,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4188793,
     "sourceId": 7233781,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4188797,
     "sourceId": 7233797,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4188807,
     "sourceId": 7233809,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4188838,
     "sourceId": 7233849,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4188854,
     "sourceId": 7233871,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4188868,
     "sourceId": 7233888,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4188894,
     "sourceId": 7233925,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
